{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "# EXAMPLE FROM -- https://towardsdatascience.com/a-beginners-guide-to-word-embedding-with-gensim-word2vec-model-5970fa56cc92\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html\n",
    "from gensim.models import Word2Vec\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib as mpl\n",
    "mpl.use(\"TkAgg\")\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  Make       Model  Year             Engine Fuel Type  Engine HP  \\\n0  BMW  1 Series M  2011  premium unleaded (required)      335.0   \n1  BMW    1 Series  2011  premium unleaded (required)      300.0   \n2  BMW    1 Series  2011  premium unleaded (required)      300.0   \n3  BMW    1 Series  2011  premium unleaded (required)      230.0   \n4  BMW    1 Series  2011  premium unleaded (required)      230.0   \n\n   Engine Cylinders Transmission Type     Driven_Wheels  Number of Doors  \\\n0               6.0            MANUAL  rear wheel drive              2.0   \n1               6.0            MANUAL  rear wheel drive              2.0   \n2               6.0            MANUAL  rear wheel drive              2.0   \n3               6.0            MANUAL  rear wheel drive              2.0   \n4               6.0            MANUAL  rear wheel drive              2.0   \n\n                         Market Category Vehicle Size Vehicle Style  \\\n0  Factory Tuner,Luxury,High-Performance      Compact         Coupe   \n1                     Luxury,Performance      Compact   Convertible   \n2                Luxury,High-Performance      Compact         Coupe   \n3                     Luxury,Performance      Compact         Coupe   \n4                                 Luxury      Compact   Convertible   \n\n   highway MPG  city mpg  Popularity   MSRP  \n0           26        19        3916  46135  \n1           28        19        3916  40650  \n2           28        20        3916  36350  \n3           28        18        3916  29450  \n4           28        18        3916  34500  \n"
     ]
    }
   ],
   "source": [
    "cars_df = pd.read_csv(\"./data/cars/data.csv\")\n",
    "print(cars_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['premium unleaded (required)', 'MANUAL', 'rear wheel drive', 'Factory Tuner', 'Luxury', 'High-Performance', 'Compact', 'Coupe', 'BMW 1 Series M'], ['premium unleaded (required)', 'MANUAL', 'rear wheel drive', 'Luxury', 'Performance', 'Compact', 'Convertible', 'BMW 1 Series']]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "cars_df['Maker_Model']= cars_df['Make']+ \" \" + cars_df['Model']\n",
    "\n",
    "# Select features from original dataset to form a new dataframe\n",
    "df1 = cars_df[['Engine Fuel Type','Transmission Type','Driven_Wheels','Market Category','Vehicle Size', 'Vehicle Style', 'Maker_Model']]\n",
    "\n",
    "# For each row, combine all the columns into one column\n",
    "df2 = df1.apply(lambda x: ','.join(x.astype(str)), axis=1)\n",
    "\n",
    "# Store them in a pandas dataframe\n",
    "df_clean = pd.DataFrame({'clean': df2})\n",
    "\n",
    "# Create the list of list format of the custom corpus for gensim modeling \n",
    "sent = [row.split(',') for row in df_clean['clean']]\n",
    "\n",
    "# show the example of list of list format of the custom corpus for gensim modeling \n",
    "print(sent[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can train the genism word2vec model with our own custom corpus as following:\n",
    "# sg: The training algorithm, either CBOW(0) or skip gram(1). The default training algorithm is CBOW.\n",
    "model = Word2Vec(sent, min_count=1,size= 50,workers=3, window =3, sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-1.29781663e-02 -1.02103718e-01  1.80753286e-03  1.51702585e-02\n  2.88857728e-01  1.88896850e-01  3.33204679e-02 -3.05914968e-01\n  9.96626839e-02 -1.98564708e-01  2.88734157e-02 -6.58230949e-03\n -7.07473606e-02  2.66958147e-01 -9.41700935e-02  2.12716847e-03\n  9.76487324e-02 -1.13655008e-01  8.78906474e-02 -2.19511688e-01\n  7.51455128e-02 -1.96342304e-01  1.54801518e-01  8.25967342e-02\n  2.77260020e-02  1.44463271e-01  6.89573810e-02 -2.35848054e-01\n -2.16182787e-04 -8.44315737e-02 -4.31028642e-02  5.13898842e-02\n  8.93378630e-02  8.22694302e-02  5.23096509e-02  5.94185367e-02\n  1.91950440e-01 -3.78317125e-02  1.16712198e-01  1.89329356e-01\n  2.39873677e-01 -7.46561289e-02 -4.00127377e-03  1.44083649e-01\n  7.43657351e-02  8.89398530e-02 -6.53699487e-02  7.09899962e-02\n -1.05344616e-01  1.45446556e-02]\n[ 0.00290547 -0.01530276 -0.00397836  0.0088531   0.04609529  0.03686055\n  0.01683452 -0.04237878  0.00708837 -0.03303989  0.01541901  0.00848634\n -0.02950245  0.04444623 -0.0005655  -0.00047488  0.00499166 -0.02795824\n  0.01782423 -0.04682232  0.01132572 -0.01571499  0.0441905   0.00796084\n -0.00112488  0.01543339  0.01288549 -0.0192521  -0.0026044   0.00178738\n -0.0135205   0.00544743  0.00183355  0.01625495 -0.0014499  -0.00733495\n  0.05471234  0.01538145  0.01990443  0.01620643  0.02675326 -0.00669017\n  0.00941118  0.00683411 -0.01286621  0.00825139 -0.01695788  0.02410634\n -0.02168889  0.01516553]\n"
     ]
    }
   ],
   "source": [
    "print(model['Toyota Camry'])\n",
    "print(model['BMW 1 Series M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.87314415\n0.9877105\n[('Toyota MR2 Spyder', 0.9953170418739319), ('Mercedes-Benz SL-Class', 0.9949602484703064), ('Honda S2000', 0.9938086271286011), ('Chrysler Crossfire', 0.9937037825584412), ('BMW 1 Series', 0.993675947189331)]\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('Porsche 718 Cayman', 'Nissan Van'))\n",
    "print(model.similarity('Porsche 718 Cayman', 'Mercedes-Benz SLK-Class'))\n",
    "print(model.most_similar('Mercedes-Benz SLK-Class')[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance (model, word,target_list , num) :\n",
    "    cosine_dict ={}\n",
    "    word_list = []\n",
    "    a = model[word]\n",
    "    for item in target_list :\n",
    "        if item != word :\n",
    "            b = model [item]\n",
    "            cos_sim = np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "            cosine_dict[item] = cos_sim\n",
    "    dist_sort=sorted(cosine_dict.items(), key=lambda dist: dist[1],reverse = True) ## in Descedning order \n",
    "    for item in dist_sort:\n",
    "        word_list.append((item[0], item[1]))\n",
    "    return word_list[0:num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('Toyota MR2 Spyder', 0.99531704), ('Mercedes-Benz SL-Class', 0.9949602), ('Honda S2000', 0.99380875), ('Chrysler Crossfire', 0.9937039), ('BMW 1 Series', 0.993676)]\n"
     ]
    }
   ],
   "source": [
    "# only get the unique Maker_Models\n",
    "Maker_Model = list(cars_df.Maker_Model.unique()) \n",
    "\n",
    "# Show the most similar Mercedes-Benz SLK-Class by cosine distance\n",
    "cd = cosine_distance (model,'Mercedes-Benz SLK-Class',Maker_Model,5)\n",
    "print(cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_closestwords_tsnescatterplot(model, word, size):\n",
    "    arr = np.empty((0,size), dtype='f')\n",
    "    word_labels = [word]\n",
    "\n",
    "    close_words = model.similar_by_word(word)\n",
    "    arr = np.append(arr, np.array([model[word]]), axis=0)\n",
    "    for wrd_score in close_words:\n",
    "        wrd_vector = model[wrd_score[0]]\n",
    "        word_labels.append(wrd_score[0])\n",
    "        arr = np.append(arr, np.array([wrd_vector]), axis=0)\n",
    "        \n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    np.set_printoptions(suppress=True)\n",
    "    Y = tsne.fit_transform(arr)\n",
    "    x_coords = Y[:, 0]\n",
    "    y_coords = Y[:, 1]\n",
    "    plt.scatter(x_coords, y_coords)\n",
    "    for label, x, y in zip(word_labels, x_coords, y_coords):\n",
    "        plt.annotate(label, xy=(x, y), xytext=(0, 0), textcoords='offset points')\n",
    "    plt.xlim(x_coords.min()+0.00005, x_coords.max()+0.00005)\n",
    "    plt.ylim(y_coords.min()+0.00005, y_coords.max()+0.00005)\n",
    "    plt.show()\n",
    "\n",
    "display_closestwords_tsnescatterplot(model, 'Porsche 718 Cayman', 50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}